{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c0070218",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Index 24399의 모든 Value ===\n",
            "\n",
            "'sid':\n",
            "  Type: <class 'int'>\n",
            "  Value: 1022903\n",
            "\n",
            "'primitive_slab':\n",
            "  Type: <class 'pymatgen.io.ase.MSONAtoms'>\n",
            "  Length: 32\n",
            "  Value (first 10 items): [Atom('Re', [np.float64(1.1086056232452401), np.float64(5.760484059651693), np.float64(6.788795381784439)], index=0), Atom('Re', [np.float64(1.1086056232452406), np.float64(8.3207000096639), np.float64(3.168104559183122)], index=1), Atom('Re', [np.float64(1.1086056232452393), np.float64(0.6400540669759126), np.float64(3.1681045591831216)], index=2), Atom('Re', [np.float64(1.1086056232452397), np.float64(3.200269063313803), np.float64(10.409486383199692)], index=3), Atom('Re', [np.float64(1.1086056232452397), np.float64(3.200269063313803), np.float64(4.978450208902361)], index=4), Atom('Re', [np.float64(1.1086056232452401), np.float64(5.760484059651693), np.float64(1.357758909463883)], index=5), Atom('Re', [np.float64(1.1086056232452406), np.float64(8.3207000096639), np.float64(8.599140793085098)], index=6), Atom('Re', [np.float64(1.1086056232452393), np.float64(0.6400540669759126), np.float64(8.599140793085098)], index=7), Atom('Re', [np.float64(3.3258168697357187), np.float64(4.480376561482748), np.float64(3.168104559183122)], index=8), Atom('Re', [np.float64(3.325816869735719), np.float64(7.040591557820639), np.float64(10.409486383199692)], index=9)]\n",
            "  ... (total 32 items)\n",
            "\n",
            "'supercell_matrix':\n",
            "  Type: <class 'numpy.ndarray'>\n",
            "  Shape: (3, 3)\n",
            "  Dtype: int64\n",
            "  Value:\n",
            "[[-2  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 0 -1  0]]\n",
            "\n",
            "'n_slab':\n",
            "  Type: <class 'int'>\n",
            "  Value: 1\n",
            "\n",
            "'n_vac':\n",
            "  Type: <class 'int'>\n",
            "  Value: 2\n",
            "\n",
            "'ads_atomic_numbers':\n",
            "  Type: <class 'numpy.ndarray'>\n",
            "  Shape: (4,)\n",
            "  Dtype: int64\n",
            "  Value:\n",
            "[6 1 1 8]\n",
            "\n",
            "'ads_pos':\n",
            "  Type: <class 'numpy.ndarray'>\n",
            "  Shape: (4, 3)\n",
            "  Dtype: float64\n",
            "  Value:\n",
            "[[ -3.20369601 -11.65157827  -2.24321398]\n",
            " [ -2.23816478 -12.16047986  -2.39303145]\n",
            " [ -4.07111573 -12.29815229  -2.44936833]\n",
            " [ -3.28979349 -11.12933286  -0.87605366]]\n",
            "\n",
            "'ref_energy':\n",
            "  Type: <class 'float'>\n",
            "  Value: -2.4266686500000105\n",
            "\n",
            "'ref_ads_pos':\n",
            "  Type: <class 'numpy.ndarray'>\n",
            "  Shape: (4, 3)\n",
            "  Dtype: float64\n",
            "  Value:\n",
            "[[ 0.62365  0.24565  0.3742 ]\n",
            " [ 1.28305 -0.45015  0.918  ]\n",
            " [-0.30655  0.45035  0.928  ]\n",
            " [ 1.30655  1.45015  0.072  ]]\n",
            "\n",
            "'bind_ads_atom':\n",
            "  Type: <class 'numpy.int64'>\n",
            "  Value: 6\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import lmdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# LMDB 파일 경로\n",
        "lmdb_path = \"/home/minkyu/MinCatFlow/dataset/val_id/dataset.lmdb\"\n",
        "\n",
        "# 특정 index 설정\n",
        "target_index = 24399  # 원하는 index로 변경\n",
        "\n",
        "# LMDB 열기\n",
        "env = lmdb.open(\n",
        "    lmdb_path,\n",
        "    subdir=False,\n",
        "    readonly=True,\n",
        "    lock=False,\n",
        "    readahead=True,\n",
        "    meminit=False,\n",
        "    max_readers=1,\n",
        ")\n",
        "\n",
        "# 특정 index의 데이터 가져오기\n",
        "with env.begin() as txn:\n",
        "    # 키를 문자열로 변환 (index를 키로 사용)\n",
        "    key_str = str(target_index)\n",
        "    key_bytes = key_str.encode(\"ascii\")\n",
        "    \n",
        "    # 해당 키의 값 가져오기\n",
        "    value = txn.get(key_bytes)\n",
        "    \n",
        "    if value is None:\n",
        "        print(f\"Index {target_index}에 해당하는 데이터를 찾을 수 없습니다.\")\n",
        "    else:\n",
        "        # pickle로 역직렬화\n",
        "        data_dict = pickle.loads(value)\n",
        "        \n",
        "        print(f\"=== Index {target_index}의 모든 Value ===\\n\")\n",
        "        \n",
        "        # 모든 키-값 쌍 출력\n",
        "        for key, value in data_dict.items():\n",
        "            print(f\"'{key}':\")\n",
        "            print(f\"  Type: {type(value)}\")\n",
        "            \n",
        "            if isinstance(value, np.ndarray):\n",
        "                print(f\"  Shape: {value.shape}\")\n",
        "                print(f\"  Dtype: {value.dtype}\")\n",
        "                if value.size < 50:  # 작은 배열은 전체 출력\n",
        "                    print(f\"  Value:\\n{value}\")\n",
        "                else:\n",
        "                    print(f\"  Value (first 20 elements):\\n{value.flat[:20]}\")\n",
        "                    print(f\"  ... (total {value.size} elements)\")\n",
        "            elif hasattr(value, '__len__') and not isinstance(value, str):\n",
        "                try:\n",
        "                    print(f\"  Length: {len(value)}\")\n",
        "                    if len(value) < 20:\n",
        "                        print(f\"  Value: {value}\")\n",
        "                    else:\n",
        "                        print(f\"  Value (first 10 items): {list(value)[:10]}\")\n",
        "                        print(f\"  ... (total {len(value)} items)\")\n",
        "                except:\n",
        "                    print(f\"  Value: {value}\")\n",
        "            elif hasattr(value, 'positions'):  # ASE.Atoms 객체인 경우\n",
        "                print(f\"  Number of atoms: {len(value)}\")\n",
        "                print(f\"  Positions shape: {value.positions.shape}\")\n",
        "                print(f\"  Numbers (atomic numbers): {value.numbers}\")\n",
        "                print(f\"  Cell shape: {value.cell.shape}\")\n",
        "                if hasattr(value, 'get_chemical_symbols'):\n",
        "                    symbols = value.get_chemical_symbols()\n",
        "                    print(f\"  Chemical symbols (first 20): {symbols[:20]}\")\n",
        "                    if len(symbols) > 20:\n",
        "                        print(f\"  ... (total {len(symbols)} atoms)\")\n",
        "            else:\n",
        "                print(f\"  Value: {value}\")\n",
        "            print()\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee608ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ase.atoms import Atoms\n",
        "import numpy as np\n",
        "from scripts.assemble import assemble\n",
        "from pymatgen.io.ase import AseAtomsAdaptor\n",
        "import math \n",
        "from ase.build import niggli_reduce\n",
        "from pymatgen.core.lattice import Lattice\n",
        "from ase.cell import Cell\n",
        "\n",
        "adaptor = AseAtomsAdaptor()\n",
        "\n",
        "# 위에서 추출한 데이터를 사용하여 atoms 객체 생성\n",
        "# data_dict는 위 셀에서 이미 로드되어 있다고 가정\n",
        "# 1. Primitive slab atoms 객체 (이미 atoms 객체이므로 그대로 사용 가능)\n",
        "primitive_slab_atoms = data_dict[\"primitive_slab\"]\n",
        "ads_atomic_numbers = data_dict[\"ads_atomic_numbers\"]  # [7, 1] (N, H)\n",
        "ads_pos = data_dict[\"ads_pos\"]  # (2, 3) 좌표\n",
        "supercell_matrix = data_dict[\"supercell_matrix\"]\n",
        "\n",
        "n_slab = data_dict[\"n_slab\"]\n",
        "n_vac = data_dict[\"n_vac\"]\n",
        "scaling_factor = (n_slab + n_vac) / n_slab\n",
        "\n",
        "# prim_slab_struct = adaptor.get_structure(primitive_slab_atoms)\n",
        "\n",
        "# sc_matrix = supercell_matrix\n",
        "\n",
        "# print(f\"Supercell matrix:\\n{sc_matrix}\")\n",
        "\n",
        "# recon_struct = prim_slab_struct.copy()\n",
        "# recon_struct.make_supercell(sc_matrix, to_unit_cell=False)\n",
        "\n",
        "# recon_tight_slab = adaptor.get_atoms(recon_struct)\n",
        "\n",
        "# recon_slab = recon_tight_slab.copy()\n",
        "# recon_cell = recon_slab.get_cell()\n",
        "# recon_cell[2] = recon_cell[2] * scaling_factor\n",
        "# recon_slab.set_cell(recon_cell)\n",
        "\n",
        "# adsorbate = Atoms(\n",
        "#     positions=ads_pos,\n",
        "#     numbers=ads_atomic_numbers,\n",
        "#     cell=recon_cell,\n",
        "#     pbc=True,\n",
        "# )\n",
        "\n",
        "# recon_system = recon_slab + adsorbate\n",
        "\n",
        "recon_system = assemble(\n",
        "    primitive_slab_atoms.get_positions(),\n",
        "    ads_pos,\n",
        "    primitive_slab_atoms.get_cell_lengths_and_angles(),\n",
        "    supercell_matrix,\n",
        "    scaling_factor,\n",
        "    primitive_slab_atoms.get_atomic_numbers(),\n",
        "    ads_atomic_numbers,\n",
        ")\n",
        "\n",
        "print(\"recon_system lattice (matrix form):\\n\", recon_system.get_cell())\n",
        "\n",
        "from ase.visualize import view\n",
        "\n",
        "view(recon_system, viewer='x3d')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d342102",
      "metadata": {},
      "outputs": [],
      "source": [
        "import lmdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# LMDB 파일 경로\n",
        "lmdb_path = \"/home/minkyu/EfficientCatGen/dataset/train/dataset.lmdb\"\n",
        "output_dir = \"/home/minkyu/EfficientCatGen/analysis_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 모든 ads_pos 수집\n",
        "all_ads_pos = []  # 모든 원자 좌표를 펼쳐서 저장\n",
        "all_ads_pos_per_sample = []  # 샘플별로 저장 (outlier 탐지용)\n",
        "sample_indices = []\n",
        "\n",
        "env = lmdb.open(\n",
        "    lmdb_path,\n",
        "    subdir=False,\n",
        "    readonly=True,\n",
        "    lock=False,\n",
        "    readahead=True,\n",
        "    meminit=False,\n",
        "    max_readers=1,\n",
        ")\n",
        "\n",
        "with env.begin() as txn:\n",
        "    # 전체 데이터 개수 확인\n",
        "    length = txn.stat()[\"entries\"]\n",
        "    print(f\"Total samples in dataset: {length}\")\n",
        "    \n",
        "    for idx in tqdm(range(length), desc=\"Loading ads_pos\"):\n",
        "        key_bytes = str(idx).encode(\"ascii\")\n",
        "        value = txn.get(key_bytes)\n",
        "        \n",
        "        if value is None:\n",
        "            continue\n",
        "            \n",
        "        data_dict = pickle.loads(value)\n",
        "        ads_pos = data_dict.get(\"ads_pos\", None)\n",
        "        \n",
        "        if ads_pos is not None and len(ads_pos) > 0:\n",
        "            all_ads_pos.append(ads_pos)\n",
        "            all_ads_pos_per_sample.append({\n",
        "                \"idx\": idx,\n",
        "                \"ads_pos\": ads_pos,\n",
        "                \"mean\": np.mean(ads_pos, axis=0),\n",
        "                \"std\": np.std(ads_pos),\n",
        "                \"min\": np.min(ads_pos, axis=0),\n",
        "                \"max\": np.max(ads_pos, axis=0),\n",
        "                \"n_atoms\": len(ads_pos),\n",
        "            })\n",
        "            sample_indices.append(idx)\n",
        "\n",
        "env.close()\n",
        "\n",
        "# 모든 좌표를 하나의 배열로 합치기\n",
        "all_coords = np.vstack(all_ads_pos)\n",
        "print(f\"\\nTotal adsorbate atoms: {len(all_coords)}\")\n",
        "print(f\"Total samples with adsorbate: {len(all_ads_pos_per_sample)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ce89b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 1. 기본 통계 분석\n",
        "# ========================\n",
        "print(\"=\" * 60)\n",
        "print(\"1. Basic Statistics of ads_pos (all atoms)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, axis in enumerate([\"X\", \"Y\", \"Z\"]):\n",
        "    coords = all_coords[:, i]\n",
        "    print(f\"\\n{axis}-axis:\")\n",
        "    print(f\"  Min: {np.min(coords):.4f}\")\n",
        "    print(f\"  Max: {np.max(coords):.4f}\")\n",
        "    print(f\"  Mean: {np.mean(coords):.4f}\")\n",
        "    print(f\"  Std: {np.std(coords):.4f}\")\n",
        "    print(f\"  Median: {np.median(coords):.4f}\")\n",
        "    \n",
        "    # Percentiles\n",
        "    p1, p5, p25, p75, p95, p99 = np.percentile(coords, [1, 5, 25, 75, 95, 99])\n",
        "    print(f\"  Percentiles: 1%={p1:.2f}, 5%={p5:.2f}, 25%={p25:.2f}, 75%={p75:.2f}, 95%={p95:.2f}, 99%={p99:.2f}\")\n",
        "\n",
        "# ========================\n",
        "# 2. Outlier 탐지 (IQR 방법)\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"2. Outlier Detection (IQR method, 1.5*IQR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "outlier_samples = []\n",
        "for i, axis in enumerate([\"X\", \"Y\", \"Z\"]):\n",
        "    coords = all_coords[:, i]\n",
        "    Q1 = np.percentile(coords, 25)\n",
        "    Q3 = np.percentile(coords, 75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = (coords < lower_bound) | (coords > upper_bound)\n",
        "    n_outliers = np.sum(outliers)\n",
        "    \n",
        "    print(f\"\\n{axis}-axis:\")\n",
        "    print(f\"  IQR: {IQR:.4f}\")\n",
        "    print(f\"  Lower bound: {lower_bound:.4f}\")\n",
        "    print(f\"  Upper bound: {upper_bound:.4f}\")\n",
        "    print(f\"  Number of outliers: {n_outliers} ({100*n_outliers/len(coords):.2f}%)\")\n",
        "    \n",
        "    if n_outliers > 0:\n",
        "        outlier_values = coords[outliers]\n",
        "        print(f\"  Outlier range: [{np.min(outlier_values):.2f}, {np.max(outlier_values):.2f}]\")\n",
        "\n",
        "# ========================\n",
        "# 3. 샘플별 통계 분석 (centroid 기준)\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"3. Per-sample Statistics (centroid of each adsorbate)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "centroids = np.array([s[\"mean\"] for s in all_ads_pos_per_sample])\n",
        "for i, axis in enumerate([\"X\", \"Y\", \"Z\"]):\n",
        "    coords = centroids[:, i]\n",
        "    print(f\"\\n{axis}-axis (centroids):\")\n",
        "    print(f\"  Min: {np.min(coords):.4f}, Max: {np.max(coords):.4f}\")\n",
        "    print(f\"  Mean: {np.mean(coords):.4f}, Std: {np.std(coords):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010e6d7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 4. 2D Projection Plots (XY, YZ, ZX)\n",
        "# ========================\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# XY plane\n",
        "ax = axes[0]\n",
        "ax.scatter(all_coords[:, 0], all_coords[:, 1], alpha=0.1, s=1, c='blue')\n",
        "ax.set_xlabel('X (Å)', fontsize=12)\n",
        "ax.set_ylabel('Y (Å)', fontsize=12)\n",
        "ax.set_title('XY Plane Projection', fontsize=14)\n",
        "ax.set_aspect('equal')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# YZ plane\n",
        "ax = axes[1]\n",
        "ax.scatter(all_coords[:, 1], all_coords[:, 2], alpha=0.1, s=1, c='green')\n",
        "ax.set_xlabel('Y (Å)', fontsize=12)\n",
        "ax.set_ylabel('Z (Å)', fontsize=12)\n",
        "ax.set_title('YZ Plane Projection', fontsize=14)\n",
        "ax.set_aspect('equal')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# ZX plane\n",
        "ax = axes[2]\n",
        "ax.scatter(all_coords[:, 2], all_coords[:, 0], alpha=0.1, s=1, c='red')\n",
        "ax.set_xlabel('Z (Å)', fontsize=12)\n",
        "ax.set_ylabel('X (Å)', fontsize=12)\n",
        "ax.set_title('ZX Plane Projection', fontsize=14)\n",
        "ax.set_aspect('equal')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('ads_pos 2D Projections (All Atoms)', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/ads_pos_2d_projections.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Saved: {output_dir}/ads_pos_2d_projections.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce296f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 5. Histograms for X, Y, Z coordinates\n",
        "# ========================\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "colors = ['blue', 'green', 'red']\n",
        "labels = ['X', 'Y', 'Z']\n",
        "\n",
        "for i, (ax, color, label) in enumerate(zip(axes, colors, labels)):\n",
        "    coords = all_coords[:, i]\n",
        "    \n",
        "    ax.hist(coords, bins=100, color=color, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
        "    ax.axvline(np.mean(coords), color='black', linestyle='--', linewidth=2, label=f'Mean: {np.mean(coords):.2f}')\n",
        "    ax.axvline(np.median(coords), color='orange', linestyle='-.', linewidth=2, label=f'Median: {np.median(coords):.2f}')\n",
        "    \n",
        "    ax.set_xlabel(f'{label} (Å)', fontsize=12)\n",
        "    ax.set_ylabel('Count', fontsize=12)\n",
        "    ax.set_title(f'{label}-coordinate Distribution', fontsize=14)\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('ads_pos Coordinate Distributions', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/ads_pos_histograms.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Saved: {output_dir}/ads_pos_histograms.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42656322",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 6. 2D Density Heatmaps (더 나은 시각화)\n",
        "# ========================\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# XY plane heatmap\n",
        "ax = axes[0]\n",
        "h = ax.hist2d(all_coords[:, 0], all_coords[:, 1], bins=100, cmap='viridis', cmin=1)\n",
        "plt.colorbar(h[3], ax=ax, label='Count')\n",
        "ax.set_xlabel('X (Å)', fontsize=12)\n",
        "ax.set_ylabel('Y (Å)', fontsize=12)\n",
        "ax.set_title('XY Plane Density', fontsize=14)\n",
        "\n",
        "# YZ plane heatmap\n",
        "ax = axes[1]\n",
        "h = ax.hist2d(all_coords[:, 1], all_coords[:, 2], bins=100, cmap='viridis', cmin=1)\n",
        "plt.colorbar(h[3], ax=ax, label='Count')\n",
        "ax.set_xlabel('Y (Å)', fontsize=12)\n",
        "ax.set_ylabel('Z (Å)', fontsize=12)\n",
        "ax.set_title('YZ Plane Density', fontsize=14)\n",
        "\n",
        "# ZX plane heatmap\n",
        "ax = axes[2]\n",
        "h = ax.hist2d(all_coords[:, 2], all_coords[:, 0], bins=100, cmap='viridis', cmin=1)\n",
        "plt.colorbar(h[3], ax=ax, label='Count')\n",
        "ax.set_xlabel('Z (Å)', fontsize=12)\n",
        "ax.set_ylabel('X (Å)', fontsize=12)\n",
        "ax.set_title('ZX Plane Density', fontsize=14)\n",
        "\n",
        "plt.suptitle('ads_pos 2D Density Heatmaps', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/ads_pos_2d_heatmaps.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Saved: {output_dir}/ads_pos_2d_heatmaps.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa344a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 7. Outlier 샘플 식별 (극단적인 좌표를 가진 샘플)\n",
        "# ========================\n",
        "print(\"=\" * 60)\n",
        "print(\"7. Identifying Outlier Samples\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 전체 데이터에서 통계 계산\n",
        "global_mean = np.mean(all_coords, axis=0)\n",
        "global_std = np.std(all_coords, axis=0)\n",
        "\n",
        "print(f\"\\nGlobal mean: X={global_mean[0]:.2f}, Y={global_mean[1]:.2f}, Z={global_mean[2]:.2f}\")\n",
        "print(f\"Global std:  X={global_std[0]:.2f}, Y={global_std[1]:.2f}, Z={global_std[2]:.2f}\")\n",
        "\n",
        "# Z-score 기반 outlier 탐지 (|z| > 3)\n",
        "outlier_threshold = 3.0\n",
        "outlier_samples_info = []\n",
        "\n",
        "for sample in all_ads_pos_per_sample:\n",
        "    ads_pos = sample[\"ads_pos\"]\n",
        "    z_scores = np.abs((ads_pos - global_mean) / (global_std + 1e-8))\n",
        "    max_z = np.max(z_scores)\n",
        "    \n",
        "    if max_z > outlier_threshold:\n",
        "        outlier_samples_info.append({\n",
        "            \"idx\": sample[\"idx\"],\n",
        "            \"max_z_score\": max_z,\n",
        "            \"mean\": sample[\"mean\"],\n",
        "            \"min\": sample[\"min\"],\n",
        "            \"max\": sample[\"max\"],\n",
        "            \"n_atoms\": sample[\"n_atoms\"],\n",
        "        })\n",
        "\n",
        "# Z-score로 정렬\n",
        "outlier_samples_info.sort(key=lambda x: x[\"max_z_score\"], reverse=True)\n",
        "\n",
        "print(f\"\\nFound {len(outlier_samples_info)} samples with |z-score| > {outlier_threshold}\")\n",
        "print(f\"\\nTop 20 outlier samples:\")\n",
        "print(\"-\" * 100)\n",
        "print(f\"{'Idx':<8} {'Max Z':<10} {'N_atoms':<8} {'Mean X':<12} {'Mean Y':<12} {'Mean Z':<12}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for info in outlier_samples_info[:20]:\n",
        "    print(f\"{info['idx']:<8} {info['max_z_score']:<10.2f} {info['n_atoms']:<8} \"\n",
        "          f\"{info['mean'][0]:<12.2f} {info['mean'][1]:<12.2f} {info['mean'][2]:<12.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc79819a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 8. Centroid Distribution (샘플별 adsorbate 중심 위치)\n",
        "# ========================\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "centroids = np.array([s[\"mean\"] for s in all_ads_pos_per_sample])\n",
        "\n",
        "# XY plane\n",
        "ax = axes[0]\n",
        "ax.scatter(centroids[:, 0], centroids[:, 1], alpha=0.3, s=5, c='blue')\n",
        "ax.set_xlabel('X (Å)', fontsize=12)\n",
        "ax.set_ylabel('Y (Å)', fontsize=12)\n",
        "ax.set_title('Centroid XY Projection', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# YZ plane\n",
        "ax = axes[1]\n",
        "ax.scatter(centroids[:, 1], centroids[:, 2], alpha=0.3, s=5, c='green')\n",
        "ax.set_xlabel('Y (Å)', fontsize=12)\n",
        "ax.set_ylabel('Z (Å)', fontsize=12)\n",
        "ax.set_title('Centroid YZ Projection', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# ZX plane\n",
        "ax = axes[2]\n",
        "ax.scatter(centroids[:, 2], centroids[:, 0], alpha=0.3, s=5, c='red')\n",
        "ax.set_xlabel('Z (Å)', fontsize=12)\n",
        "ax.set_ylabel('X (Å)', fontsize=12)\n",
        "ax.set_title('Centroid ZX Projection', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Adsorbate Centroid Distributions (per sample)', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/ads_pos_centroid_projections.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Saved: {output_dir}/ads_pos_centroid_projections.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f189b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 9. 좌표 범위 분석 (학습 관점)\n",
        "# ========================\n",
        "print(\"=\" * 60)\n",
        "print(\"9. Coordinate Range Analysis (Training Perspective)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 좌표 범위\n",
        "coord_range = np.max(all_coords, axis=0) - np.min(all_coords, axis=0)\n",
        "print(f\"\\nCoordinate Ranges:\")\n",
        "print(f\"  X range: {coord_range[0]:.2f} Å ({np.min(all_coords[:,0]):.2f} to {np.max(all_coords[:,0]):.2f})\")\n",
        "print(f\"  Y range: {coord_range[1]:.2f} Å ({np.min(all_coords[:,1]):.2f} to {np.max(all_coords[:,1]):.2f})\")\n",
        "print(f\"  Z range: {coord_range[2]:.2f} Å ({np.min(all_coords[:,2]):.2f} to {np.max(all_coords[:,2]):.2f})\")\n",
        "\n",
        "# 샘플 내 adsorbate 크기 (internal spread)\n",
        "internal_stds = np.array([s[\"std\"] for s in all_ads_pos_per_sample])\n",
        "print(f\"\\nAdsorbate Internal Spread (std per sample):\")\n",
        "print(f\"  Mean: {np.mean(internal_stds):.4f} Å\")\n",
        "print(f\"  Std: {np.std(internal_stds):.4f} Å\")\n",
        "print(f\"  Min: {np.min(internal_stds):.4f} Å\")\n",
        "print(f\"  Max: {np.max(internal_stds):.4f} Å\")\n",
        "\n",
        "# 문제점 분석\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"10. Potential Issues for Learning\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "1. 좌표 범위가 매우 넓음:\n",
        "   - X: {coord_range[0]:.1f} Å, Y: {coord_range[1]:.1f} Å, Z: {coord_range[2]:.1f} Å\n",
        "   - 이렇게 넓은 범위를 학습하려면 모델이 큰 값들을 처리해야 함\n",
        "\n",
        "2. Standardization 부재:\n",
        "   - 현재 ads_pos는 mean/std standardization 없이 raw Cartesian 좌표 사용\n",
        "   - 좌표가 centering되어 있지 않음 (mean ≠ 0)\n",
        "\n",
        "3. 권장 사항:\n",
        "   - ads_pos에도 standardization 적용 검토\n",
        "   - 또는 adsorbate centroid를 기준으로 centering 후 학습\n",
        "   \n",
        "4. Global Statistics (for standardization):\n",
        "   - Mean: X={global_mean[0]:.4f}, Y={global_mean[1]:.4f}, Z={global_mean[2]:.4f}\n",
        "   - Std:  X={global_std[0]:.4f}, Y={global_std[1]:.4f}, Z={global_std[2]:.4f}\n",
        "\"\"\")\n",
        "\n",
        "# 통계를 파일로 저장\n",
        "stats_dict = {\n",
        "    \"global_mean\": global_mean.tolist(),\n",
        "    \"global_std\": global_std.tolist(),\n",
        "    \"coord_range\": coord_range.tolist(),\n",
        "    \"total_atoms\": len(all_coords),\n",
        "    \"total_samples\": len(all_ads_pos_per_sample),\n",
        "}\n",
        "\n",
        "import json\n",
        "with open(f\"{output_dir}/ads_pos_statistics.json\", \"w\") as f:\n",
        "    json.dump(stats_dict, f, indent=2)\n",
        "print(f\"\\nSaved statistics to: {output_dir}/ads_pos_statistics.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f30bc20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# Train dataset structural validity 검사\n",
        "# ========================\n",
        "import lmdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ase import Atoms\n",
        "from scripts.assemble import assemble\n",
        "\n",
        "def structural_validity(atoms: Atoms) -> dict:\n",
        "    \"\"\"Check structural validity of an Atoms object and return detailed results.\"\"\"\n",
        "    results = {\"valid\": True, \"vol_ok\": True, \"dist_ok\": True, \"width_ok\": True}\n",
        "    \n",
        "    # 1. Check cell volume\n",
        "    try:\n",
        "        vol = float(atoms.get_volume())\n",
        "        results[\"vol_ok\"] = vol >= 0.1\n",
        "        results[\"volume\"] = vol\n",
        "    except Exception:\n",
        "        results[\"vol_ok\"] = False\n",
        "        results[\"volume\"] = None\n",
        "\n",
        "    # 2. Check atom clash\n",
        "    try:\n",
        "        if len(atoms) > 1:\n",
        "            dists = atoms.get_all_distances()\n",
        "            min_dist = np.min(dists[np.nonzero(dists)])\n",
        "            results[\"dist_ok\"] = min_dist >= 0.5\n",
        "            results[\"min_dist\"] = min_dist\n",
        "        else:\n",
        "            results[\"dist_ok\"] = True\n",
        "            results[\"min_dist\"] = None\n",
        "    except Exception:\n",
        "        results[\"dist_ok\"] = False\n",
        "        results[\"min_dist\"] = None\n",
        "    \n",
        "    # 3. Check min width of cell (a, b >= 8.0 Å)\n",
        "    min_ab = 8.0\n",
        "    a_length = np.linalg.norm(atoms.cell[0])\n",
        "    b_length = np.linalg.norm(atoms.cell[1])\n",
        "    results[\"a_length\"] = a_length\n",
        "    results[\"b_length\"] = b_length\n",
        "    results[\"width_ok\"] = (a_length >= min_ab) and (b_length >= min_ab)\n",
        "\n",
        "    # 4. Overall validity\n",
        "    results[\"valid\"] = results[\"vol_ok\"] and results[\"dist_ok\"] and results[\"width_ok\"]\n",
        "    \n",
        "    return results\n",
        "\n",
        "# LMDB 파일 경로\n",
        "lmdb_path = \"/home/minkyu/EfficientCatGen/dataset/train/dataset.lmdb\"\n",
        "\n",
        "# 통계 수집\n",
        "total_samples = 0\n",
        "valid_samples = 0\n",
        "invalid_reasons = {\"vol\": 0, \"dist\": 0, \"width\": 0}\n",
        "failed_samples = []\n",
        "\n",
        "env = lmdb.open(\n",
        "    lmdb_path,\n",
        "    subdir=False,\n",
        "    readonly=True,\n",
        "    lock=False,\n",
        "    readahead=True,\n",
        "    meminit=False,\n",
        "    max_readers=1,\n",
        ")\n",
        "\n",
        "with env.begin() as txn:\n",
        "    length = txn.stat()[\"entries\"]\n",
        "    print(f\"Total samples in dataset: {length}\")\n",
        "    \n",
        "    for idx in tqdm(range(length), desc=\"Checking structural validity\"):\n",
        "        key_bytes = str(idx).encode(\"ascii\")\n",
        "        value = txn.get(key_bytes)\n",
        "        \n",
        "        if value is None:\n",
        "            continue\n",
        "        \n",
        "        total_samples += 1\n",
        "        \n",
        "        try:\n",
        "            data_dict = pickle.loads(value)\n",
        "            \n",
        "            # Extract data\n",
        "            primitive_slab = data_dict[\"primitive_slab\"]\n",
        "            supercell_matrix = data_dict[\"supercell_matrix\"]\n",
        "            n_slab = data_dict[\"n_slab\"]\n",
        "            n_vac = data_dict[\"n_vac\"]\n",
        "            ads_atomic_numbers = data_dict.get(\"ads_atomic_numbers\", np.array([]))\n",
        "            ads_pos = data_dict.get(\"ads_pos\", np.array([]).reshape(0, 3))\n",
        "            \n",
        "            # Calculate scaling factor\n",
        "            scaling_factor = (n_slab + n_vac) / n_slab\n",
        "            \n",
        "            # Get primitive slab info\n",
        "            prim_positions = primitive_slab.get_positions()\n",
        "            prim_numbers = primitive_slab.get_atomic_numbers()\n",
        "            lattice_params = primitive_slab.cell.cellpar()  # (a, b, c, alpha, beta, gamma)\n",
        "            \n",
        "            # Use assemble function from scripts/assemble.py\n",
        "            recon_system = assemble(\n",
        "                generated_prim_slab_coords=prim_positions,\n",
        "                generated_ads_coords=ads_pos,\n",
        "                generated_lattice=lattice_params,\n",
        "                generated_supercell_matrix=supercell_matrix,\n",
        "                generated_scaling_factor=scaling_factor,\n",
        "                prim_slab_atom_types=prim_numbers,\n",
        "                ads_atom_types=ads_atomic_numbers,\n",
        "            )\n",
        "            \n",
        "            # Check structural validity\n",
        "            validity = structural_validity(recon_system)\n",
        "            \n",
        "            if validity[\"valid\"]:\n",
        "                valid_samples += 1\n",
        "            else:\n",
        "                if not validity[\"vol_ok\"]:\n",
        "                    invalid_reasons[\"vol\"] += 1\n",
        "                if not validity[\"dist_ok\"]:\n",
        "                    invalid_reasons[\"dist\"] += 1\n",
        "                if not validity[\"width_ok\"]:\n",
        "                    invalid_reasons[\"width\"] += 1\n",
        "                \n",
        "                # Store first few failed samples for inspection\n",
        "                if len(failed_samples) < 10:\n",
        "                    failed_samples.append({\n",
        "                        \"idx\": idx,\n",
        "                        \"validity\": validity,\n",
        "                    })\n",
        "                    \n",
        "        except Exception as e:\n",
        "            if len(failed_samples) < 10:\n",
        "                failed_samples.append({\"idx\": idx, \"error\": str(e)})\n",
        "\n",
        "env.close()\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Structural Validity Results\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nTotal samples: {total_samples}\")\n",
        "print(f\"Valid samples: {valid_samples}\")\n",
        "print(f\"Invalid samples: {total_samples - valid_samples}\")\n",
        "print(f\"\\nValidity rate: {100 * valid_samples / total_samples:.2f}%\")\n",
        "\n",
        "print(f\"\\n--- Invalid Reasons (can overlap) ---\")\n",
        "print(f\"  Volume < 0.1: {invalid_reasons['vol']} ({100 * invalid_reasons['vol'] / total_samples:.2f}%)\")\n",
        "print(f\"  Min distance < 0.5 Å: {invalid_reasons['dist']} ({100 * invalid_reasons['dist'] / total_samples:.2f}%)\")\n",
        "print(f\"  Cell width (a or b) < 8.0 Å: {invalid_reasons['width']} ({100 * invalid_reasons['width'] / total_samples:.2f}%)\")\n",
        "\n",
        "if failed_samples:\n",
        "    print(f\"\\n--- Sample Failed Cases (first {len(failed_samples)}) ---\")\n",
        "    for sample in failed_samples:\n",
        "        print(f\"  Index {sample['idx']}: {sample.get('validity', sample.get('error', 'Unknown'))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f420671",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# prim_slab_coords 와 ads_pos 의 mean/std 계산\n",
        "# (Standardization을 위한 통계)\n",
        "# ========================\n",
        "import lmdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# LMDB 파일 경로\n",
        "lmdb_path = \"/home/minkyu/EfficientCatGen/dataset/train/dataset.lmdb\"\n",
        "\n",
        "# 모든 좌표 수집\n",
        "all_prim_slab_coords = []\n",
        "all_ads_coords = []\n",
        "\n",
        "env = lmdb.open(\n",
        "    lmdb_path,\n",
        "    subdir=False,\n",
        "    readonly=True,\n",
        "    lock=False,\n",
        "    readahead=True,\n",
        "    meminit=False,\n",
        "    max_readers=1,\n",
        ")\n",
        "\n",
        "with env.begin() as txn:\n",
        "    length = txn.stat()[\"entries\"]\n",
        "    print(f\"Total samples in dataset: {length}\")\n",
        "    \n",
        "    for idx in tqdm(range(length), desc=\"Loading coordinates\"):\n",
        "        key_bytes = str(idx).encode(\"ascii\")\n",
        "        value = txn.get(key_bytes)\n",
        "        \n",
        "        if value is None:\n",
        "            continue\n",
        "            \n",
        "        data_dict = pickle.loads(value)\n",
        "        \n",
        "        # Primitive slab coordinates\n",
        "        prim_slab = data_dict.get(\"primitive_slab\", None)\n",
        "        if prim_slab is not None:\n",
        "            # MSONAtoms에서 positions 추출\n",
        "            positions = prim_slab.get_positions()  # (N, 3)\n",
        "            all_prim_slab_coords.append(positions)\n",
        "        \n",
        "        # Adsorbate coordinates\n",
        "        ads_pos = data_dict.get(\"ads_pos\", None)\n",
        "        if ads_pos is not None and len(ads_pos) > 0:\n",
        "            all_ads_coords.append(ads_pos)\n",
        "\n",
        "env.close()\n",
        "\n",
        "# 모든 좌표를 하나의 배열로 합치기\n",
        "all_prim_slab_flat = np.vstack(all_prim_slab_coords)\n",
        "all_ads_flat = np.vstack(all_ads_coords)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Statistics for Standardization\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# ========================\n",
        "# prim_slab_coords 통계\n",
        "# ========================\n",
        "print(f\"\\n[prim_slab_coords]\")\n",
        "print(f\"  Total atoms: {len(all_prim_slab_flat)}\")\n",
        "print(f\"  Total samples: {len(all_prim_slab_coords)}\")\n",
        "\n",
        "prim_slab_mean = np.mean(all_prim_slab_flat, axis=0)\n",
        "prim_slab_std = np.std(all_prim_slab_flat, axis=0)\n",
        "prim_slab_global_std = np.std(all_prim_slab_flat)  # 전체 std (scalar)\n",
        "\n",
        "print(f\"\\n  Per-axis Mean: [{prim_slab_mean[0]:.6f}, {prim_slab_mean[1]:.6f}, {prim_slab_mean[2]:.6f}]\")\n",
        "print(f\"  Per-axis Std:  [{prim_slab_std[0]:.6f}, {prim_slab_std[1]:.6f}, {prim_slab_std[2]:.6f}]\")\n",
        "print(f\"  Global Std (scalar): {prim_slab_global_std:.6f}\")\n",
        "\n",
        "# ========================\n",
        "# ads_pos 통계\n",
        "# ========================\n",
        "print(f\"\\n[ads_pos]\")\n",
        "print(f\"  Total atoms: {len(all_ads_flat)}\")\n",
        "print(f\"  Total samples: {len(all_ads_coords)}\")\n",
        "\n",
        "ads_mean = np.mean(all_ads_flat, axis=0)\n",
        "ads_std = np.std(all_ads_flat, axis=0)\n",
        "ads_global_std = np.std(all_ads_flat)  # 전체 std (scalar)\n",
        "\n",
        "print(f\"\\n  Per-axis Mean: [{ads_mean[0]:.6f}, {ads_mean[1]:.6f}, {ads_mean[2]:.6f}]\")\n",
        "print(f\"  Per-axis Std:  [{ads_std[0]:.6f}, {ads_std[1]:.6f}, {ads_std[2]:.6f}]\")\n",
        "print(f\"  Global Std (scalar): {ads_global_std:.6f}\")\n",
        "\n",
        "# ========================\n",
        "# Config 형식으로 출력 (복사용)\n",
        "# ========================\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Config Format (copy-paste ready)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"\"\"\n",
        "# prim_slab_coords standardization\n",
        "prim_slab_coord_mean: [{prim_slab_mean[0]:.6f}, {prim_slab_mean[1]:.6f}, {prim_slab_mean[2]:.6f}]\n",
        "prim_slab_coord_std: [{prim_slab_std[0]:.6f}, {prim_slab_std[1]:.6f}, {prim_slab_std[2]:.6f}]\n",
        "# or use global std (recommended for isotropic scaling):\n",
        "prim_slab_coord_global_std: {prim_slab_global_std:.6f}\n",
        "\n",
        "# ads_pos standardization\n",
        "ads_coord_mean: [{ads_mean[0]:.6f}, {ads_mean[1]:.6f}, {ads_mean[2]:.6f}]\n",
        "ads_coord_std: [{ads_std[0]:.6f}, {ads_std[1]:.6f}, {ads_std[2]:.6f}]\n",
        "# or use global std (recommended for isotropic scaling):\n",
        "ads_coord_global_std: {ads_global_std:.6f}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de953ed7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import lmdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# LMDB 파일 경로\n",
        "lmdb_path = \"/home/minkyu/EfficientCatGen/is2res_train_val_test_lmdbs/data/is2re/all/val_id/data.lmdb\"\n",
        "\n",
        "# 특정 index 설정\n",
        "target_index = 0  # 원하는 index로 변경\n",
        "\n",
        "# LMDB 열기\n",
        "env = lmdb.open(\n",
        "    lmdb_path,\n",
        "    subdir=False,\n",
        "    readonly=True,\n",
        "    lock=False,\n",
        "    readahead=True,\n",
        "    meminit=False,\n",
        "    max_readers=1,\n",
        ")\n",
        "\n",
        "# 특정 index의 데이터 가져오기\n",
        "with env.begin() as txn:\n",
        "    # 키를 문자열로 변환 (index를 키로 사용)\n",
        "    key_str = str(target_index)\n",
        "    key_bytes = key_str.encode(\"ascii\")\n",
        "    \n",
        "    # 해당 키의 값 가져오기\n",
        "    value = txn.get(key_bytes)\n",
        "    \n",
        "    if value is None:\n",
        "        print(f\"Index {target_index}에 해당하는 데이터를 찾을 수 없습니다.\")\n",
        "    else:\n",
        "        # pickle로 역직렬화\n",
        "        data_dict = pickle.loads(value)\n",
        "        \n",
        "        print(f\"=== Index {target_index}의 모든 Value ===\\n\")\n",
        "        \n",
        "        # 모든 키-값 쌍 출력\n",
        "        for key, value in data_dict.items():\n",
        "            print(f\"'{key}':\")\n",
        "            print(f\"  Type: {type(value)}\")\n",
        "            \n",
        "            if isinstance(value, np.ndarray):\n",
        "                print(f\"  Shape: {value.shape}\")\n",
        "                print(f\"  Dtype: {value.dtype}\")\n",
        "                if value.size < 50:  # 작은 배열은 전체 출력\n",
        "                    print(f\"  Value:\\n{value}\")\n",
        "                else:\n",
        "                    print(f\"  Value (first 20 elements):\\n{value.flat[:20]}\")\n",
        "                    print(f\"  ... (total {value.size} elements)\")\n",
        "            elif hasattr(value, '__len__') and not isinstance(value, str):\n",
        "                try:\n",
        "                    print(f\"  Length: {len(value)}\")\n",
        "                    if len(value) < 20:\n",
        "                        print(f\"  Value: {value}\")\n",
        "                    else:\n",
        "                        print(f\"  Value (first 10 items): {list(value)[:10]}\")\n",
        "                        print(f\"  ... (total {len(value)} items)\")\n",
        "                except:\n",
        "                    print(f\"  Value: {value}\")\n",
        "            elif hasattr(value, 'positions'):  # ASE.Atoms 객체인 경우\n",
        "                print(f\"  Number of atoms: {len(value)}\")\n",
        "                print(f\"  Positions shape: {value.positions.shape}\")\n",
        "                print(f\"  Numbers (atomic numbers): {value.numbers}\")\n",
        "                print(f\"  Cell shape: {value.cell.shape}\")\n",
        "                if hasattr(value, 'get_chemical_symbols'):\n",
        "                    symbols = value.get_chemical_symbols()\n",
        "                    print(f\"  Chemical symbols (first 20): {symbols[:20]}\")\n",
        "                    if len(symbols) > 20:\n",
        "                        print(f\"  ... (total {len(symbols)} atoms)\")\n",
        "            else:\n",
        "                print(f\"  Value: {value}\")\n",
        "            print()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2388b259",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# adsorbates.pkl 파일 경로\n",
        "pkl_path = \"/home/minkyu/EfficientCatGen/adsorbates.pkl\"\n",
        "\n",
        "# pickle 파일 로드\n",
        "with open(pkl_path, \"rb\") as f:\n",
        "    adsorbates_data = pickle.load(f)\n",
        "\n",
        "print(f\"=== adsorbates.pkl 파일 내용 ===\\n\")\n",
        "print(f\"데이터 타입: {type(adsorbates_data)}\\n\")\n",
        "\n",
        "# 데이터 타입에 따라 다르게 처리\n",
        "if isinstance(adsorbates_data, dict):\n",
        "    print(f\"딕셔너리 키 개수: {len(adsorbates_data)}\")\n",
        "    print(f\"키 목록: {list(adsorbates_data.keys())}\\n\")\n",
        "    \n",
        "    for key, value in adsorbates_data.items():\n",
        "        print(f\"'{key}':\")\n",
        "        print(f\"  Type: {type(value)}\")\n",
        "        \n",
        "        if isinstance(value, np.ndarray):\n",
        "            print(f\"  Shape: {value.shape}\")\n",
        "            print(f\"  Dtype: {value.dtype}\")\n",
        "            if value.size < 50:\n",
        "                print(f\"  Value:\\n{value}\")\n",
        "            else:\n",
        "                print(f\"  Value (first 20 elements):\\n{value.flat[:20]}\")\n",
        "                print(f\"  ... (total {value.size} elements)\")\n",
        "        elif isinstance(value, (list, tuple)):\n",
        "            print(f\"  Length: {len(value)}\")\n",
        "            if len(value) < 20:\n",
        "                print(f\"  Value: {value}\")\n",
        "            else:\n",
        "                print(f\"  Value (first 10 items): {list(value)[:10]}\")\n",
        "                print(f\"  ... (total {len(value)} items)\")\n",
        "        else:\n",
        "            print(f\"  Value: {value}\")\n",
        "        print()\n",
        "\n",
        "elif isinstance(adsorbates_data, (list, tuple)):\n",
        "    print(f\"리스트/튜플 길이: {len(adsorbates_data)}\\n\")\n",
        "    for i, item in enumerate(adsorbates_data[:10]):  # 처음 10개만 출력\n",
        "        print(f\"[{i}]:\")\n",
        "        print(f\"  Type: {type(item)}\")\n",
        "        if isinstance(item, np.ndarray):\n",
        "            print(f\"  Shape: {item.shape}\")\n",
        "            print(f\"  Dtype: {item.dtype}\")\n",
        "            if item.size < 20:\n",
        "                print(f\"  Value:\\n{item}\")\n",
        "            else:\n",
        "                print(f\"  Value (first 10 elements): {item.flat[:10]}\")\n",
        "        else:\n",
        "            print(f\"  Value: {item}\")\n",
        "        print()\n",
        "    if len(adsorbates_data) > 10:\n",
        "        print(f\"... (total {len(adsorbates_data)} items)\\n\")\n",
        "\n",
        "elif isinstance(adsorbates_data, np.ndarray):\n",
        "    print(f\"배열 Shape: {adsorbates_data.shape}\")\n",
        "    print(f\"Dtype: {adsorbates_data.dtype}\")\n",
        "    if adsorbates_data.size < 50:\n",
        "        print(f\"\\n전체 값:\\n{adsorbates_data}\")\n",
        "    else:\n",
        "        print(f\"\\n처음 20개 요소:\\n{adsorbates_data.flat[:20]}\")\n",
        "        print(f\"... (total {adsorbates_data.size} elements)\")\n",
        "\n",
        "else:\n",
        "    print(f\"값: {adsorbates_data}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b8e30b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import sys\n",
        "\n",
        "file_path = 'oc20_data_mapping.pkl'\n",
        "\n",
        "try:\n",
        "    # 바이너리 읽기 모드로 파일 열기\n",
        "    with open(file_path, 'rb') as f:\n",
        "        print(f\"Loading {file_path}...\")\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # 데이터 타입 확인\n",
        "    print(f\"Data type: {type(data)}\")\n",
        "\n",
        "    # 데이터가 딕셔너리인 경우\n",
        "    if isinstance(data, dict):\n",
        "        if len(data) > 0:\n",
        "            # 전체를 순회하지 않고 첫 번째 키만 가져옴 (메모리 효율 및 속도)\n",
        "            first_key = next(iter(data))\n",
        "            first_value = data[first_key]\n",
        "            \n",
        "            print(\"\\n--- First Item ---\")\n",
        "            print(f\"Key: {first_key}\")\n",
        "            print(f\"Value: {first_value}\")\n",
        "        else:\n",
        "            print(\"The dictionary is empty.\")\n",
        "            \n",
        "    # 데이터가 리스트인 경우 (참고용)\n",
        "    elif isinstance(data, list):\n",
        "        if len(data) > 0:\n",
        "            print(\"\\n--- First Item (List) ---\")\n",
        "            print(data[0])\n",
        "        else:\n",
        "            print(\"The list is empty.\")\n",
        "            \n",
        "    else:\n",
        "        print(\"The data is not a dictionary or list.\")\n",
        "        # 데이터의 앞부분만 살짝 출력 (문자열 변환 후 슬라이싱)\n",
        "        print(f\"Preview: {str(data)[:200]}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
